<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://matthijsmu.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://matthijsmu.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-01-09T15:40:26+00:00</updated><id>https://matthijsmu.github.io/feed.xml</id><title type="html">blank</title><subtitle>Matthijs Muis, Undergraduate student Mathematics, Computer Science at Radboud University Nijmegen. Portfolio + Teaching + Blog + Personal Stuff. </subtitle><entry><title type="html">Pipes</title><link href="https://matthijsmu.github.io/blog/2023/pipes/" rel="alternate" type="text/html" title="Pipes"/><published>2023-09-19T00:00:00+00:00</published><updated>2023-09-19T00:00:00+00:00</updated><id>https://matthijsmu.github.io/blog/2023/pipes</id><content type="html" xml:base="https://matthijsmu.github.io/blog/2023/pipes/"><![CDATA[<h2 id="introduction-chaining-commands-in-bash">Introduction: chaining commands in <code class="language-plaintext highlighter-rouge">bash</code></h2> <p>In <code class="language-plaintext highlighter-rouge">bash</code>, we can chain commands, for example</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">date</span> | <span class="nb">tail</span> <span class="nt">-c</span> 5
</code></pre></div></div> <p>will redirect the stdout of the <code class="language-plaintext highlighter-rouge">date</code> command to the stdin of <code class="language-plaintext highlighter-rouge">tail -c 5</code>, and this will take the last 5 characters from its stdin stream (including the newline character <code class="language-plaintext highlighter-rouge">\n</code>) and display these to its stdout.</p> <p>More specifically, every command in the pipeline is run in a separate process, and their standard inputs and outputs are connected via a pipe. See <a href="https://www.gnu.org/software/bash/manual/bash.html#Pipelines">GNUs bash manual</a> for the details.</p> <p>Pipes are constructs created and managed by the operating system. On unix-like operating systems, they are created with the system call <code class="language-plaintext highlighter-rouge">pipe()</code>.</p> <p>This post will look into an implementation of a simple shell in <code class="language-plaintext highlighter-rouge">c++</code> that supports chaining of commands and redirection of input/output streams of the first/last command in the chain.</p> <h2 id="file-descriptors">File descriptors</h2> <p>In the POSIX API, files and other IO resources are identified by a <em>file descriptor</em>, which is a process-unique identifier or handle, in <code class="language-plaintext highlighter-rouge">c/c++</code> usually an <code class="language-plaintext highlighter-rouge">int</code>-type.</p> <p>Such a file descriptor can be used as an argument to a <code class="language-plaintext highlighter-rouge">read()</code> or <code class="language-plaintext highlighter-rouge">write()</code> system call, which will result in an actual read or write to the file described by the fd.</p> <p>In the POSIX API, other IO resources are also described by file descriptor, and they can be passed around to the calls <code class="language-plaintext highlighter-rouge">read()</code>, <code class="language-plaintext highlighter-rouge">write()</code>, just as files. So pipes, devices, files, network sockets, all have the same uniform interface for programmers programming to the API.</p> <p>Every process should have access to three standard POSIX file descriptors at any time: <code class="language-plaintext highlighter-rouge">stdin</code>, <code class="language-plaintext highlighter-rouge">stdout</code>, and <code class="language-plaintext highlighter-rouge">stderr</code>. <code class="language-plaintext highlighter-rouge">stdin</code> is the fd for the standard input stream, <code class="language-plaintext highlighter-rouge">stdout</code> for the standard output stream and <code class="language-plaintext highlighter-rouge">stderr</code> for the error stream, where errors are printed to if they occur.</p> <p>When programming in a specific language, one has access to the POSIX API via a <em>library</em>, which is the language’s concrete interface to the API. IN <code class="language-plaintext highlighter-rouge">c/c++</code>, this library is <code class="language-plaintext highlighter-rouge">libc</code> and its functions can be found in a collection of header files. The constant file descriptors for <code class="language-plaintext highlighter-rouge">stdin</code>, <code class="language-plaintext highlighter-rouge">stdout</code>, and <code class="language-plaintext highlighter-rouge">stderr</code> are available and can be found as <code class="language-plaintext highlighter-rouge">STDIN_FILENO</code>, <code class="language-plaintext highlighter-rouge">STDOUT_FILENO</code> and <code class="language-plaintext highlighter-rouge">STDERR_FILENO</code> in the header <code class="language-plaintext highlighter-rouge">unistd.h</code></p> <p>One advantage of the uniform interface of fds describing IO resources, is that any type of output stream can be redirected to any other type of output stream, and the same goes for input streams. On POSIX we can find the system call <code class="language-plaintext highlighter-rouge">dup2()</code> that does exactly this. For example, suppose we want to redirect the stdout to a file at path <code class="language-plaintext highlighter-rouge">"relative/path/to/your/file.txt"</code>. This can be accomplished by:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">file_path</span> <span class="o">=</span> <span class="s">"relative/path/to/your/file.txt"</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">file_descriptor</span><span class="p">;</span>

    <span class="c1">// Open the file in append and write-only mode</span>
    <span class="n">file_descriptor</span> <span class="o">=</span> <span class="n">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">O_WRONLY</span> <span class="o">|</span> <span class="n">O_APPEND</span><span class="p">);</span>

    <span class="c1">// If there was an error, open will return -1, otherwise</span>
    <span class="c1">// a valid file descriptor.</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">file_descriptor</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">perror</span><span class="p">(</span><span class="s">"Error opening the file"</span><span class="p">);</span>
        <span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">dup2</span><span class="p">(</span><span class="n">file_descriptor</span><span class="p">,</span> <span class="n">STDOUT_FILENO</span><span class="p">);</span>
    <span class="p">}</span>
</code></pre></div></div> <h2 id="anonymous-pipes">(Anonymous) Pipes</h2> <p>Pipes are file descriptors that can be used for inter-process communication. A pipe is created using the system call <code class="language-plaintext highlighter-rouge">pipe(int pipefd[2])</code>, which populates an array of 2 <code class="language-plaintext highlighter-rouge">int</code>s:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">pipefd</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="kt">int</span> <span class="n">err</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span><span class="n">pipefd</span><span class="p">);</span> <span class="c1">// if error, err = -1</span>
</code></pre></div></div> <p>This pipe has a read end described by <code class="language-plaintext highlighter-rouge">pipefd[0]</code> and a write end described by <code class="language-plaintext highlighter-rouge">pipefd[1]</code>. A pipe can be understood as a buffer in kernel space: all processes for which <code class="language-plaintext highlighter-rouge">pipefd[1]</code> is open, can write to the one end. This stream is buffered until a process begins reading from <code class="language-plaintext highlighter-rouge">pipefd[0]</code>. It is usually advantageous to let processes on both ends run concurrently, so that the buffer is skimmed while being added to and doesn’t grow too long.</p> <p>After a pipe is created, we can <code class="language-plaintext highlighter-rouge">fork()</code> the process. One of the forked processes closes the read end of the pipe and the other closes the write end. We can close resources behind file descriptors with the system call <code class="language-plaintext highlighter-rouge">close(int fd)</code>.</p> <p>Closing unused resources is strictly necessary, because if a write end is still opened in some process, a reading process can never be signalled that the end of a stream is reached (i.e. <code class="language-plaintext highlighter-rouge">read(int fd)</code> will never return <code class="language-plaintext highlighter-rouge">0</code>, but instead will block and a deadlock will occur).</p> <p>The fact that a pipe has only one read end and one write end, and communication streams traverse the pipe from write to read, makes the anonymous pipe <em>unidirectional</em>. It usually only makes sense to have each end opened in only one process simultaneously.</p> <h2 id="prototypical-implementation-of-date--tail--c-5">Prototypical implementation of <code class="language-plaintext highlighter-rouge">date | tail -c 5</code></h2> <p>Let us motivate the above theory with an example implementation of the command described earlier: <code class="language-plaintext highlighter-rouge">date | tail -c 5</code>. Here is the function in <code class="language-plaintext highlighter-rouge">c++</code> that will do this:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// imports omitted for brevity</span>

<span class="c1">// framework for executing "date | tail -c 5" using raw commands</span>
<span class="c1">// two processes are created, and connected to each other</span>
<span class="kt">int</span> <span class="nf">step1</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span> <span class="p">{</span>

  <span class="c1">// create pipe that will (by forking) become a communication channel</span>
  <span class="c1">// between the two children of this process</span>
  <span class="kt">int</span> <span class="n">pipefd</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
  
  <span class="k">if</span> <span class="p">(</span><span class="n">pipe</span><span class="p">(</span><span class="n">pipefd</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"error: could not open pipe</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="n">pid_t</span> <span class="n">child1</span> <span class="o">=</span> <span class="n">fork</span><span class="p">();</span>
  <span class="c1">// from here, code is executed in two different processes</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">child1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// redirect standard output (STDOUT_FILENO) to the input of the pipe</span>
    <span class="n">dup2</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">STDOUT_FILENO</span><span class="p">);</span>
    
    <span class="c1">// free non used resources (why?)</span>
    <span class="c1">// If we do not close the ends of the pipe in a process that won't use them,</span>
    <span class="c1">// the reading process will not detect end-of-files, and the program will </span>
    <span class="n">close</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> 
    
    <span class="n">Command</span> <span class="n">cmd</span> <span class="o">=</span> <span class="p">;</span>
    <span class="n">execute_command</span><span class="p">(</span><span class="n">cmd</span><span class="p">);</span>
    <span class="c1">// display nice warning that the executable could not be found</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"error: could not find executable: %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="s">"date"</span><span class="p">);</span>
    <span class="n">abort</span><span class="p">();</span> <span class="c1">// if the executable is not found, we should abort. (why?)</span>
    <span class="c1">// because otherwise the child process will leave the `if`-block and</span>
    <span class="c1">// continues with the control flow that is reserved for the parent process only</span>
    <span class="c1">// (forking another child etc.)</span>
  <span class="p">}</span>

  <span class="c1">// since the child does not exit the `if`-statement, the next fork()</span>
  <span class="c1">// is only executed by the parent.</span>
  <span class="n">pid_t</span> <span class="n">child2</span> <span class="o">=</span> <span class="n">fork</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">child2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// redirect the output of the pipe to the standard input (STDIN_FILENO).</span>
    <span class="n">dup2</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">STDIN_FILENO</span><span class="p">);</span>
    
    <span class="c1">// free non used resources </span>
    <span class="n">close</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
    
    
    <span class="c1">// a system call for executing the command "tail -c 5"</span>
    <span class="n">execvp</span><span class="p">(</span><span class="s">"tail -c 5"</span><span class="p">);</span>
    <span class="c1">// display nice warning that the executable could not be found</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"error: could not find executable:%s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="s">"tail -c 5"</span><span class="p">);</span>
    <span class="n">abort</span><span class="p">();</span> 
  <span class="p">}</span>

  <span class="c1">// free non used resources (why?)</span>
  <span class="c1">// If we do not close the ends of the pipe in a process that won't use them,</span>
  <span class="c1">// the reading process will not detect end-of-files, and the program will </span>
  <span class="c1">// hang.</span>
  <span class="n">close</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
  <span class="n">close</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
  
  <span class="c1">// wait on child processes to finish (why both?)</span>
  <span class="c1">// According to manual </span>
  <span class="c1">//    "In the case of a terminated child, performing a wait allows</span>
  <span class="c1">//     the system to release the resources associated with  the  child;  if  a</span>
  <span class="c1">//     wait  is not performed, then the terminated child remains in a "zombie"</span>
  <span class="c1">//     state (see NOTES below)."</span>
  <span class="c1">// So it is to ensure that the child processes actually finished.</span>
  <span class="n">waitpid</span><span class="p">(</span><span class="n">child1</span><span class="p">,</span> <span class="nb">nullptr</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
  <span class="n">waitpid</span><span class="p">(</span><span class="n">child2</span><span class="p">,</span> <span class="nb">nullptr</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

</code></pre></div></div> <p>There are three other system calls that enter the play: <code class="language-plaintext highlighter-rouge">fork()</code>, <code class="language-plaintext highlighter-rouge">waitpid()</code> and <code class="language-plaintext highlighter-rouge">execvp()</code>. Forking will create new processes that each execute one of the chained commands</p> <h3 id="fork"><code class="language-plaintext highlighter-rouge">fork()</code></h3> <p>We use the system call <code class="language-plaintext highlighter-rouge">fork()</code> to fork a process. This will clone the memory (text, data, heap, stack, CPU state, open files and in fact the entire process control block) of a process, creating two processes that are completely identical but for their process id. Note that in practice, a copy of the process’ memory and PCB may only be made once one of the forked processes begins writing to parts of this memory (known as a copy-on-write mechanism), avoiding a lot of overhead that would be incurred from copying memory.</p> <p>One of the processes can be seen as “newer” in the sense that it has received a new process id. This process is referred to as the <code class="language-plaintext highlighter-rouge">child</code> process, the pre-existing process we call the parent. After the <code class="language-plaintext highlighter-rouge">fork()</code>, all remaining code (compiled as machine code) will be run in two processes separately and concurrently. Since the process control block is also copied</p> <p>The <code class="language-plaintext highlighter-rouge">fork()</code> system call will return a <code class="language-plaintext highlighter-rouge">pid_t</code> (process-id type) identifier. This return value is different for the two processes, and is the only way that the code can understand and control in which process it is being run. We can for example run a branch of code conditionally on <code class="language-plaintext highlighter-rouge">if ((int child_id = fork()) != 0) { ... }</code>, which will ensure that the code after the <code class="language-plaintext highlighter-rouge">if</code> is only run in the child process, while the parent process can go on with something else.</p> <h3 id="waitpid"><code class="language-plaintext highlighter-rouge">waitpid()</code></h3> <p>The parent process can wait for the child process to change state using the system call <code class="language-plaintext highlighter-rouge">waidpid()</code>. According to <code class="language-plaintext highlighter-rouge">man</code> the state changes are: terminate, stopped by a signal or resumed by a signal.</p> <h3 id="execvp"><code class="language-plaintext highlighter-rouge">execvp()</code></h3> <p>According to the <code class="language-plaintext highlighter-rouge">man</code>-pages,</p> <blockquote> <p>“The exec() family of functions replaces the current process image with a new process image.”</p> </blockquote> <p>meaning that the entire image (including machine code (.text), stack, .data, heap, .bss ) is replaced by another executable image. So if everything goes right, we never return from the function <code class="language-plaintext highlighter-rouge">execvp()</code> and all code after the <code class="language-plaintext highlighter-rouge">execvp()</code> line is never reached. If <code class="language-plaintext highlighter-rouge">execvp()</code> fails, we do return and have to abort the child process gracefully (if we don’t abort, the waiting parent will hang).</p> <p><code class="language-plaintext highlighter-rouge">execvp(char *const argv[])</code> calls a program with an array <code class="language-plaintext highlighter-rouge">argv</code> of pointers to null-terminated strings. The first argument is the name of the program, the following arguments are arguments to the program.</p> <h3 id="the-piping-construct">The piping construct</h3> <p>Note that we first create a pipe, then clone the process. There is still but one pipe, pointed to by file descriptors present in both the parent and two children. Remember that a child inherits open files from its parent, because its PCB is simply a clone of its parent’s PCB, and the PCB contains the list of open files. All processes that will not use the write end of the pipe must close it, and the same goes for the read end of the pipe, and all other open non-constant (i.e. <code class="language-plaintext highlighter-rouge">stdout</code>, <code class="language-plaintext highlighter-rouge">stdin</code>, <code class="language-plaintext highlighter-rouge">stderr</code>) file descriptors that are not used in that particular process.</p> <p>Next, using <code class="language-plaintext highlighter-rouge">dup2()</code> the first child will redirect the <code class="language-plaintext highlighter-rouge">stdout</code> to the write end of the pipe. In the branch executed by the second child, we do the same with the read end and <code class="language-plaintext highlighter-rouge">stdin</code>.</p> <p>Having configured the in- and outstreams appropriately, we call <code class="language-plaintext highlighter-rouge">execvp()</code> in both children, and abort if anything goes wrong. The parent needs to wait for all children to finish, just as in an ordinary shell session.</p> <h3 id="whats-next">What’s next</h3> <p>I wanted to discuss an implementation of a very simple shell <code class="language-plaintext highlighter-rouge">shell.cpp</code> that allows chaining using <code class="language-plaintext highlighter-rouge">|</code> and redirections using <code class="language-plaintext highlighter-rouge">&lt;</code> and <code class="language-plaintext highlighter-rouge">&gt;</code>, but the simple example <code class="language-plaintext highlighter-rouge">step1()</code> and all theory surrounding it has made this post rather lengthy already.</p> <p>That is why there will be a part two, where I will continue and discuss the implementation of this simple shell in a full program named <code class="language-plaintext highlighter-rouge">shell.cpp</code>. Hope to see you there.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction: chaining commands in bash]]></summary></entry><entry><title type="html">Logic, Models, Proofs</title><link href="https://matthijsmu.github.io/blog/2023/logic-model-theory/" rel="alternate" type="text/html" title="Logic, Models, Proofs"/><published>2023-08-04T00:00:00+00:00</published><updated>2023-08-04T00:00:00+00:00</updated><id>https://matthijsmu.github.io/blog/2023/logic-model-theory</id><content type="html" xml:base="https://matthijsmu.github.io/blog/2023/logic-model-theory/"><![CDATA[<h2 id="introduction-and-motivation">Introduction and Motivation</h2> <hr/> <p>As a sample blog post, I will dive into formal first-order logic.</p> <p>The idea of mathematical logic is to make a formal language \(L\) which contains all “logical sentences”, and set up rules to manipulate sentences in this language. An example of such rules are proof trees modelling natural deduction, a technique we all find very “logical” and we use in all our everyday reasoning. Basically, we formalize reasoning by formulating it as a formal system and then we will argue about the strengths and weaknesses of that system. An example would be: <em>what properties can we not express in a sentence of this-or-that form?</em> It turns out, as we will see below, that first-order logic, for example, does not have a theory that can express that its model is a well-order. We understand what a well-order is, and yet we cannot define it by using first-order sentences alone.</p> <p>Why do we want to abstract logic and then study it from a distance using the same logical reasoning that this systems tries to model? Two example reasons:</p> <ul> <li>First, to understand where our own mathematical reasoning can bring us. What <em>assumptions</em> (axioms) need to be part of a theory in order to derive certain <em>conclusions</em>? From a meta-level, what ideas can we <em>express</em> in first-order-logic? The theory of well-orders, for example, requires an axiom that states a property of subsets of a set (every subset of a well-ordered set has a least element). We will see that no equivalent statement exists in f.o.l., which is interesting: it means that we need a more expressible formal system to specify certain ideas.</li> <li>Second, we may want to automate reasoning and/or theorem-proving. To let computers do this for us, we need a formal framework to model the reasoning process. The programming language Prolog allows you to define <em>facts</em> as instances of <em>atoms</em> and <em>rules</em> as clauses of <em>atoms</em>. It bases computations on the set of its facts, the so-called <em>knowledge base</em>. As we will see, there is a very tight correspondence between Prolog’s atoms and f.o.l.’s <em>relation symbols</em>, rules and <em>wff</em>’s, the knowledge base and a <em>structure</em>, and finally between the <em>querying</em> of a Prolog program and the <em>interpretation</em> of a sentence in a model.</li> </ul> <p>What does this look like in practice? That is what I want to tell you about in this post. It will basically comprise a very brief summary of the 2nd-year course in mathematical logic one gets to study at Radboud University.</p> <h2 id="the-language">The language</h2> <hr/> <p>I will base the definitions on <d-cite key="moerdijk2018sets"></d-cite>, which was the book studied at my university. The book is super-rigorous and will start defining logical sentences in polish notation, because that uniquely fixes the structure of a sentence without the need of bracketing subclauses. Only then will they justify the bracketing notation, by tediously provjng the bijective correspondence between bracketed sentences and polish sentences.</p> <p>The book is in my opinion maybe a bit too rigorous, and I will skip this approach. You can probably justify the bracketed notation for yourself and this blog should not become more bureaucratic than a logic blog already is. Instead, I will define terms and wff’s in the way most logic textbooks approach it, that is, using some unspoken of brackets in the right place to enforce syntax.</p> <p>By the way, I assume you are familiar with some set theory. If not, the first chapter of <d-cite key="garling2013course"></d-cite> excellent and almost as rigorous as it gets for a formal introduction.</p> <blockquote> <p><strong>Definition</strong> A <em>language</em> \(L\) is a triple \((\text{con}(L),\text{fun}(L),\text{rel}(L))\), where:</p> <ul> <li>\(\text{con}(L)\) is a set of <em>constants</em> or <em>constant symbols</em>.</li> <li>\(\text{fun}(L)\) is a set of <em>function symbols</em>.</li> <li>\(\text{rel}(L)\) is a set of <em>relation symbols</em>. Every relation or function symbol comes with an <em>arity</em>, which is a number \(n\in \mathbb N _{\geq 0}\)</li> </ul> </blockquote> <p>Practically, we could do without constants and use function symbols with arity 0 instead. However, the distinction (or, different naming) is often useful in proofs that have differing cases for terms that are constants and terms that are functions applied to terms.</p> <p>As an example, we could look at the language \(L_{group}\) that has one constant, \(e\) for the identity, one function symbol \(\circ\) for group multiplication (we will write it infix, don’t worry), and no relation symbols.</p> <p>Additionally, we will use other symbols. We assume that all symbols are distinct, so that they are unambiguous to recognize in terms and formulas. These additional symbols are:</p> <ul> <li><em>Variables</em>, which is some countably infinite set of symbols</li> <li>The <em>equality symbol</em> \(=\)</li> <li>The <em>falsum</em> or <em>absurdity</em> symbol \(\bot\)</li> <li>Logical <em>connectives</em>, which are \(\land,\lor,\lnot,\rightarrow\)</li> <li><em>Quantifiers</em>, which are in f.o.l. the <em>universal</em> quantifier \(\forall\) and the <em>existential</em> quantifier \(\exists\)</li> </ul> <blockquote> <p><strong>Definition</strong> We denote the union of the set of \(L\)’s symbols, the variables, the equality symbol, falsum, the connectives and the quantifiers, \(\mathcal{C}_L\).</p> </blockquote> <blockquote> <p><strong>Definition</strong> (Kleene star notation) We denote the set of all finite strings over some alphabet \(\mathcal{A}\), \(\mathcal{A}^* = \cup_{n=0}^\infty \mathcal{A}^n\) .</p> </blockquote> <p>With the basic definitions established, we can define the <em>terms</em> of our language \(L\).</p> <h3 id="the-terms">The Terms</h3> <hr/> <blockquote> <p><strong>Definition</strong> The set of \(L\)-terms of a language \(L\) is the smallest subset \(T\) of \(\mathcal{C}^*_L\) such that:</p> <ol> <li>If \(c \in \text{con}(L)\) then \(c \in T\)</li> <li>If \(x\) is a variable then \(x \in T\)</li> <li>If \(t_1, ... , t_n \in T\) and \(f \in \text{fun}(L)\) with arity \(n\), then \(f(t_1,...,t_n) \in T\)</li> </ol> </blockquote> <p>I want to note two things:</p> <ul> <li> <p>The above objects are all (purely syntactical) strings of symbols! This is why the bracketed notation is a tad bit non-rigorous, because for example what is the exact length of such a term, do or don’t we include bracket tokens? And where do the bracket symbols \((\) come from \()\) in the first place? They are not in the alphabet!</p> </li> <li> <p>Next, why is there a “smallest subset”? The definition means “smallest” in the sense that any set that satisfies 1., 2. and 3., must contain \(T\) as a subset. Now why would such a set exist? Think about it in this way: if \(\{T_\alpha\}_{\alpha\in I}\) is some collection of sets that all satisfy 1. and 2. and 3., then \(T = \cap_{\alpha\in I}T_\alpha\) will also contain all variables and constants, and since terms that are in \(T\) are in \(T_\alpha\) for all \(\alpha\in T\), concatenation with a function symbol will keep them in all \(T_\alpha\) and hence in \(T\). That is why there must be a minimum set: if not, we take the intersection of two different minimal sets and reach a contradiction!</p> </li> </ul> <p>Finally, for readers who are familiar with formal language theory in the field of computer science, yes the language defined above is indeed a <em>context-free</em> language generated by a context-free grammar. Computer scientists would maybe also want to do something about the ambiguity in the grammar that arises when no brackets are involved. On the other hand, they might want to think of sentences as an abstract syntax tree. In that case the polish notation would again make sense, because if we define the logical language as sentences in polish notations, we get a CFG with no need for brackets, namely with the grammar rules:</p> \[T \rightsquigarrow_1 f T T ... T\] \[T \rightsquigarrow_2 c\] \[T \rightsquigarrow_3 x\] <p>Where on the right-hand side of the first rule “\(\rightsquigarrow_1\)” there are exactly \(n\) non-terminal symbols \(T\), and this rule is defined separately for every \(n\)-ary symbol \(f\in \text{fun}(L)\) (making it, in fact, a <em>rule schema</em>) and the rule “\(\rightsquigarrow_2\)” for every constant \(c\in \text{con}(L)\), and the rule “\(\rightsquigarrow_3\)” for every variable \(x\). We can show that this CFG is non-ambiguous, and a term in this notation corresponds to the depth-first traversal of the AST of the formula. You could parse this language \(T\) in linear time from left to right, I suppose.</p> <p>Next, we define what it means to substitute a term \(s\) into a constant or variable \(x\) in a given term \(t\).</p> <blockquote> <p><strong>Definition</strong> (Substitution on \(L\)-terms) For \(t, s \in T\) and \(x\) a variable or a constant of \(L\): We define \(t[s/x]\), the <em>substitution of</em> \(s\) <em>for</em> \(x\) <em>in</em> \(t\), as:</p> <ul> <li>if \(t = f(t_1, ..., t_n)\) for some \(n\)-ary function symbol \(f\) and terms \(t_1, ... , t_n \in T\), then \(t[s/x] = f(t_1[s/x], ... , t_n[s/x])\).</li> <li>if \(t\) is a constant or a variable, then if \(t = x\) we have \(t[s/x] = s\) and otherwise \(t[s/x] = t\)</li> </ul> </blockquote> <p>We can prove by <em>structural</em> induction on terms that this immediately implies that \(t[s/x]\) is again in \(T\) for \(t,s\in T\) and \(x\) a constant or variable. The principle of structural induction means that we have to prove the statement for all constants and variables \(t\) and also that the statement holds for \(f(t_1, ... t_n) \in T\) for all \(f\in \text{fun}(L)\) \(n\)-ary, if it already holds for \(t_1, ... t_n\).</p> <h3 id="the-formulas">The formulas</h3> <hr/> <p>For \(L\)-formulas, we give a very similar definition that makes use of \(L\)-terms.</p> <blockquote> <p><strong>Definition</strong> The set of formulas \(F\) of a language \(L\) is the smallest subset of \(\mathcal{C}_L^*\) satisfying:</p> <ul> <li>It contains all <em>atomic formulas</em>, which are strings of the form: <ol> <li>\(t = s\) for \(s, t \in T\).</li> <li>\(R(t_1, ..., t_n)\) for \(R \in \text{rel}(L)\) an \(n\)-ary relation symbol and \(t_1,...,t_n\in T\).</li> <li>\(\bot\).</li> </ol> </li> <li>It contains all strings of the form: <ol> <li>\(\varphi \land \psi\), \(\varphi \lor \psi\), \(\varphi \rightarrow \psi\), \(\lnot \varphi\), for \(\varphi, \psi \in F\).</li> <li>\(\forall x \varphi\), \(\exists x \varphi\) for \(x\) a variable, \(\psi \in F\).</li> </ol> </li> </ul> </blockquote> <p>The reason that this is well-defined is because again, when a collection of sets satisfying 1. to 5. is intersected, this intersection satisfies 1. to 5. as well.</p> <p>The set of formulas, when we regard them as written in their polish notation, is again a non-ambiguous context-free language. We can think of them as being generated by:</p> \[F \rightsquigarrow \land F F\] \[F \rightsquigarrow \lor F F\] \[F \rightsquigarrow \rightarrow F F\] \[F \rightsquigarrow \lnot F\] \[F \rightsquigarrow \exists x F\] \[F \rightsquigarrow \forall x F\] \[F \rightsquigarrow = T T\] \[F \rightsquigarrow r T T ... T\] \[F \rightsquigarrow \bot\] <p>The last rule is again a <em>rule schema</em> that is defined for every \(n\)-ary relation symbol \(r\in \text{rel}(L)\). On the right-hand side of the \(\rightsquigarrow\), we have precisely \(n\) nonterminals \(T\). The grammar for \(T\) has been shown above.</p> <p>By minimality of the set of \(L\)-formulas, we can have an induction principle on \(F\), just like we had on \(T\)! That is:</p> <blockquote> <p><strong>Induction Principle on Formulas</strong> If some statement holds for all atomic formulas, and if we have that (if the statement holds for \(\varphi \in F\) and \(\psi \in F\), then it holds for \(\varphi \land \psi\), \(\varphi \lor \psi\), \(\varphi \rightarrow \psi\), \(\lnot \varphi\), \(\forall x \varphi\) and for \(\exists x \varphi\) for \(x\)), then the statement holds for all \(L\)-formulas. <strong>Proof</strong> Let \(E\) be the set of \(L\)-formulas for which the statement holds. Since it is given that \(E\) satisfies 1. to 5., it follows by minimality of \(F\) that \(F\subset E\), so we are done.</p> </blockquote> <p>With this induction principle, it is now simple to prove a recursion principle:</p> <blockquote> <p><strong>Recursion Principle on Formulas</strong> Let \(V\) be the set of variables, \(A\) the set of atomic formulas and \(X\) some arbitrary set, with functions: \(f_a:A \rightarrow X\) \(f_\land, f_\lor, f_\rightarrow: X\times X\rightarrow X\) \(f_\lnot: X \rightarrow X\) \(f_\forall, f_\exists: V\times X \rightarrow X\) Then there is a unique function \(f: F\rightarrow X\) that satisfies: \(f(\varphi) = f_a(\varphi)\) if \(\varphi\) is atomic \(f(\varphi) = f_\land(f(\chi), f(\psi))\) if \(\varphi\) is \(\chi \land \psi\) \(f(\varphi) = f_\lor(f(\chi), f(\psi))\) if \(\varphi\) is \(\chi \lor \psi\) \(f(\varphi) = f_\rightarrow(f(\chi), f(\psi))\) if \(\varphi\) is \(\chi \rightarrow \psi\) \(f(\varphi) = f_\lnot(f(\psi))\) if \(\varphi\) is \(\lnot \psi\) \(f(\varphi) = f_\forall(x, f(\psi))\) if \(\varphi\) is \(\forall x \psi\) \(f(\varphi) = f_\exists(x, f(\psi))\) if \(\varphi\) is \(\exists x \psi\)</p> </blockquote> <p>Note: try not to confuse (meta) equalities the <em>equality symbol</em> that is used inside the sentences!</p> <blockquote> <p><strong>Proof</strong> (Sketch)</p> <ul> <li>Unicity: let \(f,g\) both satisfy the recursion and let \(\psi\) be the <em>shortest</em> formula for which \(f(\psi) \not = g(\psi)\). If \(\psi\) is atomic, we see that this is not possible because \(f,g\) are both fixed as \(f_a\) on atomic formulas. So \(\psi\) is composite. We can exhaust all cases and in every case we have to conclude that not all shorter subformula of \(\psi\) can have the exact same image under \(f\) as under \(g\), hence \(\psi\) is not shortest and we get a contradiction.</li> </ul> </blockquote> <p>This means we can now safely define functions by recursion on formulas. The principle example of this is of course substitution:</p> <blockquote> <p><strong>Substitution on \(L\)-formulas</strong> For \(\varphi \in F\), \(x\in V\) and \(s\in T\), we define \(\varphi[s/x]\) by recursion:</p> <ul> <li>\(\varphi[s/x] = (t_1[s/x]=t_2[s/x])\) if \(\varphi = (t_1=t_2)\) and likewise we just substitute on terms for other atomic formulas.</li> <li>\((\psi _ \chi)[s/x] = (\psi[s/x] _ \chi[s/x])\) for \(_ \in \{\land,\lor,\rightarrow\}\)</li> <li>$$(\lnot \psi)[s/x] = \lnot(\psi[s/x])</li> <li>\((\forall y \psi)[s/x] = \forall y (\psi[s/x])\) if \(y \not = x\), otherwise \((\forall x \psi)[s/x] = \forall x \psi\)</li> <li>\((\exists y \psi)[s/x] = \exists y (\psi[s/x])\) if \(y \not = x\), otherwise \((\exists x \psi)[s/x] = \exists x \psi\)</li> </ul> </blockquote> <p>The above definition is interesting: rather than defining what a <em>bound</em> variable is and explaining why bound variables should not be substituted, we first explicitly state substitution rules, and from this we can define what it means for a variable to <em>occur</em> in a formula and to be <em>bounded</em>. A variable is bounded exactly when it is <em>not replaced by substitution</em>!</p> <blockquote> <p><strong>Definition</strong> (occurrence, bounded, free, closed) Let \(\varphi \in F\).</p> <ul> <li>An <em>occurrence</em> of \(x\in V\) in \(\varphi\) is a natural number \(i\) such that the \(i-th\) elemnt of the string \(\varphi\) is \(x\).</li> <li>If \(i\) is an occurrence of \(x\) in \(\varphi\), and let \(u\in V\) not occur in \(\varphi\). Then the occurrence \(i\) of \(x\) is called <em>bound</em> if the \(i\)-th element of \(\varphi[u/x]\) is \(x\).</li> <li><em>free</em> occurrences are those occurrences that are not bound.</li> <li>A formula that has no free occurrences of any variable \(x\in V\) is called <em>closed</em>, or also a <em>sentence</em>.</li> </ul> </blockquote> <h2 id="legitimacy-of-substitutions">Legitimacy of substitutions</h2> <p>Next, I will point out something that will immediately make you think that there is a hiat in our definitions so far. Suppose I give you the formula \(\varphi = \forall x R(x,y)\). It expresses a property for \(y\), you could say. It should mean the same as \(\forall x R(x,y)\). Yet if we substitute the term \(f(x,z)\) for \(y\), we get two formulas that seem to have wildly different semantics:</p> <blockquote> <p>\(\forall x R(x, f(x,z))\) versus \(\forall u R(u, f(x,z))\)</p> </blockquote> <p>This cannot be right. The problem is precisely that occurences of some variables (namely \(x\)) in the substituted term \(t\) get bound in \(\varphi[t/y]\). Otherwise, this bifurcation of semantics would not happen. Hence, we make this type of substitution <em>non-legitimate</em>. Closed terms (no free variables in the term, that is) are of course always legitimate to substitute.</p> <h2 id="structures-and-interpretation">Structures and interpretation</h2> <hr/> <p>So far, we have not yet spoken of the semantics or meaning of f.o.l.. Only in the previous section, I alluded to it in order to motivate legitimacy of substitutions, but I could have also thrown it at you without any motivation, and if you were naive and didn’t have an idea of what the logical connectives etcetera <em>meant</em>, we might as well have used completely different symbols with no apparent semantics such as tables, chairs and beer mugs, and once we have developed a formal system to manipulate these syntactically it would make no difference as to which relationships between the names we would be able to derive.</p> <p>But we want to do logic because we want to understand our reasoning, and we want to be sure that the abstract systems defined to study it, actually matches our interpretation (semantics) or “understanding” of logic, whatever that means. As mathematicians, we value a rigorous definition of this “interpretation” and these “semantics” as well, so we develop them using <em>model theory</em>.</p> <p>The basic idea is that we take, on our meta-level from which we study the formal wff’s, a meta-level set with on it \(n\)-ary functions and relations (not the symbols, but actual functions and relations from set theory). These we call the <em>interpretations</em> of the function and relation <em>symbols</em> in the logical sentences. We then recursively define what it means to interpret <em>terms</em>, then <em>closed formulas</em> and from this we derive a definition of truth. The development of this theory is largely attributed to Tarski. Let’s begin.</p> <blockquote> <p><strong>\(L\)-structure</strong> an \(L\)-<em>structure</em> \(M\) is a <em>nonempty</em> set \(M\) together with:</p> <ul> <li>for every constant \(c \in \text{con}(L)\) an element \(c^M\in M\).</li> <li>for every \(n\) for every \(n\)-ary function symbol \(f\in\text{fun}(L)\) a function \(f^M:M^n \rightarrow M\).</li> <li>for every \(n\) for every \(n\)-ary relation symbol \(R\in \text{rel}(L)\) a subset \(R\subset M^n\)</li> </ul> </blockquote> <p>We call \(c^M\) the interpretation of \(c\) in \(M\), and the same goes for \(f^M\) and \(R^M\). first, we define the language \(L_M\) for \(L\) a language and \(M\) an \(L\)-structure to be the language that has the same function symbols and relation symbols of \(L\), but now as its constants it has \(\text{con}(L_M) = \text{con}(L)\cup M\). As an example, we can take \(L_{ring}\), the language of rings, and consider the \(L\)-structure \(M = \mathbb{Z}_3 = \{\bar0, \bar1\, \bar3\}\). Then \(\text{con}(L_M) = \{0,1,\bar0,\bar1,\bar3\}\).</p> <p>Note that if we define \(m^M = m\in M\) for \(m\in \text{con}(L_M)\), then \(M\) is also an \(L_M\)-structure and this is how we will interpret \(L_M\)-constants in \(M\) always. This allows us to recursively define interpretations of <em>closed</em> \(L_M\)-terms:</p> <blockquote> <p><strong>Interpretation of closed terms</strong> For \(t\) an \(L_M\)-term we define the interpretation \(t^M\in M\) as:</p> <ul> <li>for \(t = f(t_1,...,t_n)\), we set \(t^M = f^M(t_1^M, ..., t_n^M)\)</li> <li>for \(t\) a constant \(c\in \text{con}(L)\), we set \(t^M = c^M\)</li> </ul> </blockquote> <p>This is well-defined and unique by structural recursion on terms. Also, note that \(t^M\in M\) can be proved by recursion on terms as well. Finally, I want to remark that there is really not much we can do to interpret <em>open</em> terms. How should we interpret an arbitrary variable anyway? Such an interpretation can for example not depend on the free variable \(x\) itself, because we want \(t[u/x]\) and \(t\) to have the same semantics, for \(u\) another variable that is not yet in \(t\).</p> <p>Next comes “Tarski’s definition of truth”. We write \(M\models\varphi\) and say that \(M\) <em>satisfies</em> \(\varphi\), \(\varphi\) <em>holds in</em> \(M\) or also that \(\varphi\) <em>is true</em> in \(M\). If not \(M\models \varphi\), that is \(M\) does not satisfy \(\varphi\), then we write \(M\not\models\varphi\).</p> <blockquote> <p><strong>Interpretation of closed formulas</strong> For a closed \(L_M\)-formula \(\varphi\) we define the relation \(M\models \varphi\) as:</p> <ul> <li>If \(\varphi\) is a closed atomic formula, it is either \(\bot\), \((t_1=t_2)\) or \(R(t_1,...,t_n)\) for \(t_1, ... , t_n\) closed \(L_M\)-terms. So define: <ul> <li>\(M\models\bot\) never holds.</li> <li>\(M\models (t_1= t_2) iff.\)t_1^M = t_2^M\(in\)M$$.</li> <li>\(M\models R(t_1, ... , t_n)\) iff \((t_1^M, ... , t_n^M )\in R^M\)</li> </ul> </li> <li>If \(\varphi\) is not atomic, it is either a connective followed by one or two closed \(L_M\)-formulas or it is one of the two quantors followed by a variable \(x\) and a \(L_M\)-formula that may have only \(x\) as a free variable but does otherwise not have any other variables with free occurences. Hence define: <ul> <li>\(M\models(\chi\land\psi)\) iff \(M\models\chi\) and \(M\models\psi\)</li> <li>\(M\models(\chi\lor\psi)\) iff \(M\models\chi\) or \(M\models\psi\)</li> <li>\(M\models(\chi\rightarrow\psi)\) iff \(M\models\psi\) whenever \(M\models\chi\)</li> <li>\(M\models(\lnot\psi)\) iff not \(M\models\psi\), hence iff \(M\not\models\psi\).</li> <li>\(M\models\forall x \psi\) iff \(M\models\psi[m/x]\) for all \(m\in M\)</li> <li>\(M\models\exists x \psi\) iff \(M\models[m/x]\) for any \(m\in M\)</li> </ul> </li> </ul> </blockquote> <blockquote> <p><strong>Validity and logical equivalence</strong></p> <ul> <li>An \(L\)-formula \(\varphi\) we call <em>valid</em> if for every \(L\)-structure \(M\) and every substitution of constants of \(M\) for free variables in \(\varphi\) we have \(M\models \varphi\).</li> <li>Two \(L\)-formulas \(\chi\) and \(\psi\) are called equivalent if the formula \(\chi\leftrightarrow\psi\) is valid.</li> </ul> </blockquote> <p>Here we have the shorthand notation \(\chi\leftrightarrow\psi \equiv (\chi\leftarrow\psi) \land (\chi\rightarrow\psi)\)</p> <p>One can then very tediously and bureaucratically prove all the logical equivalences of formulas that we already know very well intuitively, and I will not do that here.</p> <p>An \(L\)-theory \(T\) is simply a set of closed \(L\)-formulas. \(M\) is called a <em>model</em> for \(T\) if it is an \(L\)-structure that satisfies all formulas in \(T\). We call \(T\) <em>consistent</em> if it has (“admits”) a model.</p> <p>An interesting theorem says that \(T\) is consistent iff. every one of its finite subtheories is consistent. This is the so-called <em>compactness theorem</em>, which can indeed be proven via the compactness theorem from topology. Another way of proving it is with <em>ultrafilters</em>. A third way is to just use proof theory and</p> <h2 id="the-limitations-of-first-order-logic-well-orders">The limitations of first-order logic: well-orders</h2> <p>A well-order is a set \(W\) with an order relation \(\leq\) on it such that for every nonempty subset \(S\subset W\), \(S\) has a <em>least</em> element \(l\in S\), i.e. for all \(s\in S\) we have \(l\leq s\). Writing this theory in f.o.l. requires us to make a statement about all <em>subsets</em> of \(W\) rather than all <em>elements</em> of \(W\). This is nontrivial, because in the interpretation semantics we described above, we <em>quantify over the elements of a model</em>. So can it be done? The answer is no, and the proof of it makes use of the compactness theorem.</p> <blockquote> <p><strong>Compactness Theorem</strong> A theory \(T\) has a model iff. every finite \(T'\subset T\) has a model.</p> </blockquote> <p>We will use it without proof. The compactness theorem is a consequence of the completeness theorems, because proof trees are finite: \(\bot\) is true for every model of \(T\) implies by completeness that \(\bot\) can be proved from every finite subset of \(T\), and this implies by soundness that for every finite subset \(T'\) of \(T\) we have that \(T'\models \bot\).</p> <p>To show that well-orders have no first-order theory describing them, we consider the first-order formula \(\varphi_n \equiv \exists x_1 x_2 ... x_n \ x_1 &lt; x_2 &lt; ... &lt; x_n\), which expresses (in the order language \(L_{ord}\) that has the binary relation symbol \(&lt;\)) that there is an \(n\)-length strictly decreasing chain.</p> <p>Well-orders can be shown to have no infinite strictly decreasing chain \(x_1 &gt; x_2 &gt; ...\), so if the first-order theory \(T\) describes well-orders and has a model, the set of sentences \(T \cup (\cup_{n=1}^\infty \{\varphi_n\})\) does not have a model.</p> <p>But now we note that <em>any</em> finite \(T' \subset T \cup (\cup_{n=1}^\infty \{\varphi_n\})\) can only contain a <em>finite number</em> of the sentences \(\varphi_n\), hence there is a largest \(N\in mathbb N _{\geq 1}\) such that \(\varphi_N \in T'\). And thus we can take \(\mathbb N\) as a model for \(T\), since \(\mathbb N\) is a well-order and it contains for any \(N$ a\)N\(-length strictly decreasing chain, namely\)1 &lt; … &lt; N$$.</p> <p>So if \(T\) would model well-orders, then \(T \cup (\cup_{n=1}^\infty \{\varphi_n\})\) has no model on the one hand, but it has a model by compactness, which leads to a contradiction. In other words, we have shown that the property of a set being well-ordered cannot be expressed using first-order sentences!</p> <h2 id="proof-systems">Proof systems</h2> <hr/> <p>We say that \(T\models \varphi\) for \(T\) a \(L\)-theory and \(\varphi\) a \(L\)-sentence, if for every model \(M\) that satisfies \(T\)’s axioms, we have that \(M\models \varphi\).</p> <p>Many frameworks are used to <em>formally</em> prove logical sentences. For such a framework to be acceptable, we want it to be able to be able to generate a formal proof from \(T\) for all \(\varphi\) such that \(T\models\varphi\) (completeness), and vice versa we want it to not be stronger than that, that is, if \(T\vdash \varphi\) (this is the notation we will use for “there exists a proof for \(\varphi\) from assumptions in \(T\)”) then \(T\models\varphi\) (soundness).</p> <p>The set of proofs is defined as the smallest subset of the set of all <em>marked trees</em> over \(F\), that satisfies certain closure properties. I will now explain what marked trees are in this context (if you study cs/discrete maths, you are probably aware that there are 1001 definitions for trees and all sorts of variations) and what the closure properties are.</p> <blockquote> <p><strong>Tree</strong> A (rooted) tree over a set \(X\) is a finite subset \(Y\subset X\) that is:</p> <ul> <li>partially ordered,</li> <li>and has a least element,</li> <li>and for any two \(x,y\in Y\) then \(\{x,y\}\) has an upper bound iff. \(x\leq y\) or \(y\leq x\).</li> </ul> </blockquote> <p>We can display a tree as its Hasse diagram. You can then see that the third rule assures that there is no way two “upward branches” can meet again when we go up the diagram, because</p> <p>The definition given in <em>Sets, Models and Proofs</em> is somewhat different, though I believe that because \(Y\) is finite, you might be able to prove that the two definitions are equivalent:</p> <p><strong>Tree (Sets, Models, Proofs)</strong> A tree over a set \(X\) is a finite subset \(Y\subset X\) that is:</p> <blockquote> <ul> <li>partially ordered,</li> <li>for any \(x\in Y\) the set \(\downarrow (x) = \{y\in Y:y\leq x\}\) is well-ordered.</li> </ul> </blockquote> <p>The <em>maximal elements</em> \(L\subset Y\) of the tree are called <em>leaves</em>, they will act as our assumptions. Important is that assumptions can be <em>marked</em>, so we need to extend our trees to include a <em>marking function</em>.</p> <blockquote> <p><strong>Marked Tree</strong> is a tree with a function \(f:L\rightarrow \{0,1\}\) or equivalently a set \(L_{marked}\subset L\).</p> </blockquote> <p>It is very difficult to get a picture of these abstract definitions in your head. So let me include a picture of a marked tree over \(F\), some set of abstract formulas. My example also happens to be a proof tree, but I will get back to that later.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/prooftree-example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="proof tree image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>In the example, the bottom layer is the root, and the partial order relation is precisely displayed by having two formulas \(\chi\) and \(\psi\) such that \(\chi &lt; \psi\) and that there is no such \(\xi\) that \(\chi &lt; \xi &lt; \psi\) put in the diagram in such a way that \(\psi\) is on a level immediately above \(\chi\) and reachable from \(\chi\) in one step up the tree. Marked leaves are shown as elements [between rectangular brackets]. You should ignore the numbering for now, it is not part of the tree definition in any way.</p> <blockquote> <p><strong>Proof Tree</strong> Given a logical language \(L\), the set \(\mathcal T\) of proof trees is the smallest set of marked trees over the set of \(L\)-formulas that satisfies the following closure properties:</p> </blockquote> <ul> <li>Actually, you can look up the definition in the freely downloadable book <a href="https://www.a-eskwadraat.nl/Onderwijs/Boekweb/Artikel/48/Dictaat/Downloaden"><em>Sets, Models and Proofs</em></a>. I don’t want to literally copy their definition here, that feels like plagiarism.</li> <li>The general idea is that every connective and every quantor has an introduction rule to introduce it into a formula, and an elimination rule to eliminate it from a formula. Then there are assumption trees and finally a valid proof is a proof tree where all assumptions (leaves) except maybe those that occur in the <em>assumed</em> theory \(T\) and/or the formula \(\exists x (x=x)\) have been marked.</li> </ul> <p>Once you have read the above definition in the provided book, you can check for yourself that the example tree I provided earlier is indeed a proof tree. It is a proof, or better, a proof schema (since it is more of a template where \(\varphi\) is a completely abstract formula) of the <em>law of excluded third</em>. Any proof for this law makes use of \(\lnot E\), and that is also why in <em>Intuitionistic Logic</em>, where \(\lnot E\) is not one of the closure laws for proof trees, the law of excluded third does not hold.</p>]]></content><author><name></name></author><category term="logic"/><summary type="html"><![CDATA[Something about logic and models for logics (Unfinished)]]></summary></entry></feed>