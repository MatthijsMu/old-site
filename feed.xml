<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://matthijsmu.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://matthijsmu.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-08-30T17:25:39+00:00</updated><id>https://matthijsmu.github.io/feed.xml</id><title type="html">blank</title><subtitle>Matthijs Muis, Undergraduate student Mathematics, Computer Science at Radboud University Nijmegen. Portfolio + Teaching + Blog + Personal Stuff. </subtitle><entry><title type="html">Moment-Generating Functions for some discrete s.v.’s</title><link href="https://matthijsmu.github.io/blog/2023/mgf-and-discrete-sv/" rel="alternate" type="text/html" title="Moment-Generating Functions for some discrete s.v.’s"/><published>2023-08-20T00:00:00+00:00</published><updated>2023-08-20T00:00:00+00:00</updated><id>https://matthijsmu.github.io/blog/2023/mgf-and-discrete-sv</id><content type="html" xml:base="https://matthijsmu.github.io/blog/2023/mgf-and-discrete-sv/"><![CDATA[<p>We will consider some basic discrete probability models, and derive their expectance, variance and moment generating functions. My goal is to derive these in a calculus-y fashion. I hope you can fill in the analytic gaps.</p> <hr/> <p>A discrete random variable is a real random variable \(X : \Omega \rightarrow \mathbb R\), but with a <em>support</em> (we will denote the support of \(X\) by \(\mathcal X\)) \(\mathcal X \subset \mathbb Z\), that is: \(\mathbb P [X \in A] = \mathbb P [X \in A \cap \mathbb Z]\).</p> <p>We will not use the probability measure directly but always assume that random variables can be characterized by their CDF \(F_\theta: x \mapsto \mathbb P [X \leq x]\) and the associated PDF (continuous) or PMF (discrete). Moreover, we assume that the random variable is real and either discrete or with an almost everywhere continuously differentiable CDF, we will call that a continuous CDF.</p> <p>The moment generating function (MGF) of a r.v. \(X\) is defined as:</p> \[M_X(t) = \mathbb E [e^{tX}]\] <p>If the implicit integral (or sum) converges.</p> <p>If \(X_1, X_2, ...\) is a sequence of independent r.v.’s then for any \(N \in \mathbb N\) we have:</p> \[M_{X_1 + ... + X_N} (t) = \mathbb E [e^{t(X_1 + ... + X_N)}] = \mathbb E [e^{tX_1}\cdot ... \cdot e^{tX_N}]\] <p>By independence of the \(X_i\), \(e^{tX_i}\) are independent, so we can pull the product through the \(\mathbb E\) and get:</p> \[M_{X_1 + ... + X_N} (t) = \mathbb E [e^{tX_1}]\cdot ... \cdot \mathbb E [e^{tX_N}] = M_{X_1}(t) \cdot ... \cdot M_{X_N}(t)\] <p>Which will be useful when we consider convolutions later.</p> <p>A model is simply a collection of CDF’s \(\{F_\theta \mid \theta \in \Theta \}\) where all \(F_\theta\) are either continuous or discrete CDF’s, for real-valued s.v.’s \(X\).</p> <p>We will write \(f_\theta\) for the PDF or PMF corresponding with \(F_\theta\).</p> <p>I will now skip the probability theoretical bureaucracy because that belongs in a textbook rather than in a blog.</p> <hr/> <h2 id="bernoulli-or-alternative-distribution">Bernoulli or Alternative distribution</h2> <p>A probability model with a one-dimensional parameter $$p \in [0,1]</p> <p>\(X \sim \text{alt}(p)\) iff.</p> <ol> <li> \[\mathbb X = \{0,1\}\] </li> <li> \[f_p(x) = p \cdot 1_{\{x = 1\}} + (1-p) \cdot 1_{\{x = 0\}}\] </li> </ol> <p>It clearly has:</p> \[\mathbb E [X] = 1 \cdot p + 0 \cdot (1-p) = p\] \[\text {var} [X] = 1^2 \cdot p + 0^2 \cdot (1-p) - p^2 = p(1-p)\] \[M_X(t) = pe^{t\cdot 0} + (1-p) e^{t\cdot 1} = p + (1-p)e^t\] <p>The formula still holds in the edge cases \(\in \{0,1\}\).</p> <hr/> <h2 id="binomial-distribution">Binomial distribution</h2> <p>Given a two-dimensional parameter $$(n,p) \in \mathbb N \times [0,1]</p> <p>\(X \sim \text{bin}(n,p)\) iff.</p> <ol> <li> \[\mathcal X = \{0,1, ... , n\}\] </li> <li> \[f_{n,p}(x) = \binom{n}{x}p^xq^{n-x}\] </li> </ol> <p>Where we define \(q = 1-p\) (it will later become clear that this simplifies calculations).</p> <p>An equivalent definition is that \(X\) follows the distribution of \(Y_1 + ... + Y_n\), where \(Y_i \sim \text{alt}(p)\) i.i.d. You can prove this rigorously by induction on N:</p> <blockquote> <p>Induction Basis: Clearly true for \(n = 1\) Induction Step:</p> <ul> <li>Suppose \(X_{n-1}\) has the same PMF as \(Y_1 + ... + Y_{n-1}\).</li> <li>Consider \(X_n = X_{n-1} + Y_n\)</li> <li>We can calculate \(\mathbb P [X_n = x]\) by partitioning over two events: \(Y_n = 0\) and \(Y_n = 1\):</li> <li>Then \(\mathbb P [X = x] = \mathbb P [X_n = x, Y_n = 0] + \mathbb P [X_n = x, Y_n = 1] = \mathbb P [X_{n-1} = x, Y_n = 0] + \mathbb P [X_{n-1} = x-1, Y_n = 1]\)</li> <li>Since \(X_{n-1}\) is only a function of \(Y_1, ... , Y_{n-1}\), the events for \(X_{n-1}\) and \(Y_n\) are independent:</li> <li>This gives \(\mathbb P [X = x] = \mathbb P [X_{n-1} = x]\mathbb P[Y_n = 0] + \mathbb P [X_{n-1} = x-1]\mathbb P [Y_n = 1]\)</li> <li>Use the induction hypothesis to substitute \(f_{n-1,p}(x)\) and \(f_{n-1,p}(x - 1)\) into the above equality. Also fill in \(\mathbb P [Y_n = 1] = p\), \(P[Y_n = 0] = q\)</li> <li>Actually, now you can finish the proof by only some algebra! Hint: <a href="https://en.wikipedia.org/wiki/Pascal%27s_rule">Pascal’s Identity</a>.</li> </ul> </blockquote> <p>Because of this, we now have some very easy derivations for the mean, variance and MGF:</p> \[\mathbb E X = \mathbb E [ \sum_{i=1}^n Y_i ] = \sum_{i=1}^n \mathbb E Y_i = np\] \[\text{var}[X] = \sum_{i = 1} ^n \text{var}[Y_i] = npq\] \[M_X(t) = M_{Y_1}(t) \cdot ... \cdot M_{Y_n}(t) = (p + 1 e^t)^n\] <hr/> <h2 id="geometric-distribution">Geometric Distribution</h2> <p>We now have to be cautious and restrict \(p\) to the open interval: \(p \in (0,1)\).</p> <p>\(X \sim \text{geom}(p)\) iff.</p> <ol> <li> \[\mathcal X = \mathbb N_{\geq 0}\] </li> <li> \[f(x) = pq^{x-1}\] </li> </ol> <p>We can see that if \(Y_1, Y_2, ...\) is an infinite sequence of i.i.d. \(\text{alt}(p)\)-distributed r.v.’s, then \(T_1 = \min \{ k \in N_{\geq 0} \mid Y_k = 1\}\) is geometrically distributed with parameter \(p\), according to the above definition. This is because \(\mathbb P [ T_1 = x ] = \mathbb P [ Y_1 = 0, ... , Y_{k-1} = 0, Y_k = 1] = \mathbb P [ Y_1 = 0] ... \mathbb P [Y_{k-1} = 0] \mathbb P [Y_k = 1]\) by independence of the \(Y_i\)</p> <p>Where all the above derivations of expectations, variances and MGFs were done using finite sums, we now have a random variable with infinite support, and hence we are going to to do derivations using infinite series, in particular the geometric series:</p> \[\mathbb E X = \sum_{x = 1} ^ \infty xpq^{x-1}\] <p>Since \(\sum_{x = 1} ^ \infty y^{x}\) converges (absolutely) to \((1-y)^{-1}\) for all \(\vert y \vert &lt; 1\), \(\sum_{x = 1} ^ \infty py^{x}\) converges to \(p/(1-y)\), and we can even say that the series is term-wise differentiable w.r.t. \(y\) and thus has derivative \(\sum_{x = 1} ^ \infty xpy^{x-1}\), which for \(y = q\) is exactly our \(\mathbb E [X]\).</p> <p>So, we conclude \(\mathbb E X = \frac{d}{dy} \frac p {1-y} \vert_{y = q} = \frac p {(1-y)^2} \vert_{y=q} = \frac p {p^2} = p^{-1}\)</p> <p>We can do the variance in a similar way, but I will derive it via the MGF. Because if the MGF converges, it <em>generates the moments</em> of \(X\) because its taylor expansion in its variable \(t\) looks as follows::</p> \[M_X(t) = \sum_{x=0}^\infty \mathbb E [X^n] \frac {t^n} {n!}\] <p>In our case, the MGF is very simple:</p> \[M_X(t) = \sum_{x = 1} ^ \infty e^{tx} pq^{x-1} = \sum_{x = 1} ^ \infty p e^{[t+\ln(1-p)]x}\] <p>Which converges iff. \(e^{[t+\ln(1-p)]} &lt; 1\), which is the case iff. \(t &lt; -\ln(1-p)\)</p> <p>The second moment can thus be found by differentiating the MGF twice and evaluating in \(0\):</p> \[M_X '' (0) = \frac {d} {dt} \frac {pqe^t}{1 - qe^t} \vert_{t=0} = \frac {(1 - qe^t)^2pqe^t - pqe^t \cdot 2(q- qe^t) \cdot -qe^t} {(1 - qe^t)^4} \vert_{t = 0}\] \[= \frac{p^3q + 2p^2q^2} {p^4} = \frac {pq} {p^2} + \frac {2q^2} {p^2}\] <p>Then, we add in \((\mathbb E X) = (\frac q p)^2\). That will finally give us:</p> \[\text{var}[X] = \mathbb [X^2] - (\mathbb X)^2 = \frac {qp} {p^2} + \frac {q^2} {p^2} = \frac{p - p^2 + p^2 - 2p + 1} {p^2} = \frac q {p^2}\] <hr/> <h2 id="inverse-binomial-or-polya-distribution">Inverse Binomial, or Polya distribution</h2> <p>We now want to model a sequence of experiments \(Y_1, Y_2, ...\) and the distribution of the number \(T_n\) at which the \(n\)th success occurs, in other words \(T_n : = \min \{ k \in \mathbb N \mid \sum_{i = 1} ^k Y_i = n\}\) Note that the set might not have a minimum in the event that all \(Y_i\) are \(0\) before \(n\) successes are reached. This was also the case for the geometric distribution. However, \(T_n\) is non-defective: this is because the event \(\cap_{i = l}^\infty \{Y_i = 0\}\) for any \(l\) has measure 0, for we have continuity of our probability measure:</p> \[\mathbb P [\lim_{N\rightarrow \infty} A_N] = \lim_{N \rightarrow \infty} \mathbb P [A_N]\] <p>and this together with:</p> <p>\(\mathbb P[\cap_{i = l}^N \{Y_i = 0\}] = q^N\),</p> <p>implies that indeed \(\mathbb P [\cap_{i = l}^\infty \{Y_i = 0\}] = \lim_{N\rightarrow \infty} q^N = 0\).</p> <p>Lovely little derivation. And we can conclude that the support of \(T_n\) is indeed \(\mathbb N \geq n\), and we don’t need to include the value “\(\infty\)” in \(\mathcal X\) (which is done in the case of a defective r.v., then we define the event \(\{T_n = \infty\}\) to be the event “\(\{ \ \{ k \in \mathbb N \mid \sum_{i = 1} ^k Y_i = n\} = \emptyset \ \}\)”, which may not have measure 0).</p> <p>To derive the PMF, we simply note that if we set \(Z_i = \sum_{j = 1} ^i Y_j\), then \(Z_i \sim \text{bin}(i,p)\), and \(Z_i\) and \(Y_{i+1}\) are independent, so that:</p> \[f(x) = \mathbb P [Y_x = 1, Z_{x-1} = n-1] = \mathbb P [Y_x = 1]\mathbb P[ Z_{x-1} = n-1] = p \cdot \binom {x-1} {n -1} p^{x-1} q^{x-1 - (n-1)} = \binom {x-1} {n -1} p^xq^{x-n}\] <p>To derive the MGF, I will try another good trick: We can argue that the number of experiments needed for a next success, \(\{T_k - T_{k-1}\}_{1\leq k \leq n}\), is an independent set of i.i.d. \(\text{geom}(p)\) r.v.’s. In that case, if we put \(S_k := T_k - T{k-1}\) for \(1 \leq k \leq n\) (Yes, I see you, but we can simply define \(T_0 \equiv 0\)), we get:</p> \[M_{T_n} = M_{S_1}(t)\cdot ... \cdot M_{S_n}(t) = (\frac p {1 - qe^t})^n\] <p>And from this MGF we can again derive the first moment:</p> \[\mathbb E T = M'_{T_n}(0) = \frac d {dt} p^n (1 - qe^t)^{-n} = (-n)(-q)p^n(1-q)^{-n-1} = nqp^{-1} = n \mathbb E S_i\] <p>Alternatively, we can also argue that the expectation of a sum of independent variables is the sum of the expectations: \(\)\mathbb E T = n \mathbb E S_i = nqp^{-1}$$. The same holds for the variance:</p> \[\text{var}[T_n] = \sum_{i=1}^n \text{var}[S_i] = n p^{-2}q\] <hr/> <h2 id="poisson-distribution">Poisson distribution</h2> <p>What if we would consider a sequence of binomial distributions \((\text{bin}(n, p_n))_{n=0}^\infty\) such that \(n\cdot p_n \rightarrow \lambda\) as \(n\rightarrow \infty\)? You already know the answer: Poisson! Let’s skip Stirling’s approximation and the entire derivation that comes after, and state the PMF:</p> <p>We have one parameter which is usually \(\lambda\) and we require \(\lambda &gt;0\).</p> <ol> <li> \[\mathcal X = \mathbb N_{\geq0}\] </li> <li> \[f(x) = e^{-\lambda}\frac {\lambda^x}{x!}\] </li> </ol> <p>From this we can derive the MGF:</p> \[M_X(t) = \sum_{x=0}^\infty e^{tx}e^{-\lambda}\frac{\lambda^x}{x!} = e^{-\lambda}\sum_{x=0}^\infty \frac {e^{[\log(\lambda)+t]x}}{x!} = e^{-\lambda}e^{e^{[\log(\lambda)+t]}} = e^{\lambda(e^t-1)}\] <p>The first moment is \(\mathbb E X = M_X ' (0) = e^{\lambda(e^t-1)}\cdot \lambda e^t \vert_{t=0} = e^0\cdot\lambda\cdot e^0 = \lambda\)</p> <p>The second moment is \(\mathbb E X = M_X '' (0) = [\frac d {dt} e^{\lambda(e^t-1)}\cdot \lambda e^t ]_{t=0} = \lambda^2 + \lambda\), giving \(\text{var}[X] = \lambda^2 + \lambda - \lambda^2 = \lambda\) as well.</p>]]></content><author><name></name></author><category term="statistics,"/><category term="probability"/><summary type="html"><![CDATA[Let's do the derivations!]]></summary></entry><entry><title type="html">Logic, Models, Proofs</title><link href="https://matthijsmu.github.io/blog/2023/logic-model-theory/" rel="alternate" type="text/html" title="Logic, Models, Proofs"/><published>2023-08-04T00:00:00+00:00</published><updated>2023-08-04T00:00:00+00:00</updated><id>https://matthijsmu.github.io/blog/2023/logic-model-theory</id><content type="html" xml:base="https://matthijsmu.github.io/blog/2023/logic-model-theory/"><![CDATA[<h2 id="introduction-and-motivation">Introduction and Motivation</h2> <p>We will dive into formal first-order logic!</p> <p>The idea of mathematical logic is to make a formal language to express “logical sentences”, and set up rules to manipulate sentences in this language which we use to model our own everyday reasoning. Basically, we formalize reasoning and then reason about that system.</p> <p>Why formalize our reasoning? Two example reasons:</p> <ul> <li>First, to understand where our own mathematical reasoning can bring us. What <em>assumptions</em> (axioms) need to be part of a theory in order to derive certain <em>conclusions</em>? From a meta-level, what ideas can we <em>express</em> in first-order-logic? The theory of well-orders, for example, requires an axiom that states a property of subsets of a set (every subset of a well-ordered set has a least element). We will see that no equivalent statement exists in f.o.l., which is interesting: it means that we need a more expressible formal system to specify certain ideas.</li> <li>Second, we may want to automate reasoning and/or theorem-proving. To let computers do this for us, we need a formal framework to model the reasoning process. The programming language Prolog allows you to define <em>facts</em> as instances of <em>atoms</em> and <em>rules</em> as clauses of <em>atoms</em>. It bases computations on the set of its facts, the so-called <em>knowledge base</em>. As we will see, there is a very tight correspondence between Prolog’s atoms and f.o.l.’s <em>relation symbols</em>, rules and <em>wff</em>’s, the knowledge base and a <em>structure</em>, and finally between the <em>querying</em> of a Prolog program and the <em>interpretation</em> of a sentence in a model.</li> </ul> <hr/> <h2 id="defining-a-logical-language">Defining a logical language.</h2> <p>I will base the definitions on <a href="">Sets, Models and Proofs</a>, which was the book studied at my university. The book is super-rigorous and will start defining logical sentences in polish notation, because that uniquely fixes the structure of a sentence without the need of bracketing subclauses. Only then will they justify the bracketing notation, by tediously provjng the bijective correspondence between bracketed sentences and polish sentences.</p> <p>The book is in my opinion maybe a bit too rigorous, and I will skip this approach. You can probably justify the bracketed notation for yourself and this blog should not become more bureaucratic than a logic blog already is. Instead, I will define terms and wff’s in the way most logic textbooks approach it, that is, using some unspoken of brackets in the right place to enforce syntax.</p> <p>By the way, I assume you are familiar with some set theory.</p> <blockquote> <p><strong>Definition</strong> A <em>language</em> \(L\) is a triple \((\text{con}(L),\text{fun}(L),\text{rel}(L))\), where:</p> <ul> <li>\(\text{con}(L)\) is a set of <em>constants</em> or <em>constant symbols</em>.</li> <li>\(\text{fun}(L)\) is a set of <em>function symbols</em>.</li> <li>\(\text{rel}(L)\) is a set of <em>relation symbols</em>. Every relation or function symbol comes with an <em>arity</em>, which is</li> </ul> </blockquote> <p>Practically, we could do without constants and use function symbols with arity 0 instead. However, the distinction (or, different naming) is often useful in proofs that have differing cases for terms that are constants and terms that are functions applied to terms.</p> <p>As an example, we could look at the language \(L_{group}\) that has one constant, \(e\) for the identity, one function symbol \(\circ\) for group multiplication (we will write it infix, don’t worry), and no relation symbols.</p> <p>Additionally, we will use other symbols. We assume that all symbols are distinct, so that they are unambiguous to recognize in terms and formulas. These additional symbols are:</p> <ul> <li><em>Variables</em>, which is some countably infinite set of symbols</li> <li>The <em>equality symbol</em> \(=\)</li> <li>The <em>falsum</em> or <em>absurdity</em> symbol \(\bot\)</li> <li>Logical <em>connectives</em>, which are \(\land,\lor,\lnot,\rightarrow\)</li> <li><em>Quantifiers</em>, which are in f.o.l. the <em>universal</em> quantifier \(\forall\) and the <em>existential</em> quantifier \(\exists\)</li> </ul> <blockquote> <p><strong>Definition</strong> We denote the union of the set of \(L\)’s symbols, the variables, the equality symbol, falsum, the connectives and the quantifiers, \(\mathcal{C}_L\).</p> </blockquote> <blockquote> <p><strong>Definition</strong> (Kleene star notation) We denote the set of all finite strings over some alphabet \(\mathcal{A}\), \(\mathcal{A}^* = \cup_{n=0}^\infty \mathcal{A}^n\) .</p> </blockquote> <blockquote> <p><strong>Definition</strong> The set of \(L\)-terms of a language \(L\) is the smallest subset \(T\) of \(\mathcal{C}^*_L\) such that:</p> <ol> <li>If \(c \in \text{con}(L)\) then \(c \in T\)</li> <li>If \(x\) is a variable then \(x \in T\)</li> <li>If \(t_1, ... , t_n \in T\) and \(f \in \text{fun}(L)\) with arity \(n\), then \(f(t_1,...,t_n) \in T\)</li> </ol> </blockquote> <p>I want to note two things:</p> <ul> <li> <p>The above objects are all (purely syntactical) strings of symbols! This is why the bracketed notation is a tad bit non-rigorous, because for example what is the exact length of such a term if we need to know? And where do the bracket symbols \((\) come from \()\) in the first place? They are not in the alphabet!</p> </li> <li> <p>Next, why is there a “smallest subset”? The definition means “smallest” in the sense that any set that satisfies 1., 2. and 3., must contain \(T\) as a subset. Now why would such a set exist? Think about it in this way: if \(\{T_\alpha\}_{\alpha\in I}\) is some collection of sets that all satisfy 1. and 2. and 3., then \(T = \cap_{\alpha\in I}T_\alpha\) will also contain all variables and constants, and since terms that are in \(T\) are in \(T_\alpha\) for all \(\alpha\in T\), concatenation with a function symbol will keep them in all \(T_\alpha\) and hence in \(T\). That is why there must be a minimum set: if not, we take the intersection of two different minimal sets and reach a contradiction!</p> </li> </ul> <blockquote> <p><strong>Definition</strong> (Substitution on \(L\)-terms) For \(t, s \in T\) and \(x\) a variable or a constant of \(L\). We define \(t[s/x]\), the <em>substitution of</em> \(s\) <em>for</em> \(x\) <em>in</em> \(t\), as:</p> <ul> <li>if \(t = f(t_1, ..., t_n)\) for some \(n\)-ary function symbol \(f\) and terms \(t_1, ... , t_n \in T\), then $$t[s/x] = f(t_1[s/x], … , t_n[s/x]).</li> <li>if \(t\) is a constant or a variable, then if \(t = x\) we have \(t[s/x] = s\) and otherwise \(t[s/x] = t\)</li> </ul> </blockquote> <p>We can prove by <em>structural</em> induction on terms that this immediately implies that \(t[s/x]\) is again in \(T\) for \(t,s\in T\) and \(x\) a constant or variable. The principle of structural induction means that we have to prove the statement for all constants and variables \(t\) and also that the statement holds for \(f(t_1, ... t_n) \in T\) for all \(f\in \text{fun}(L)\) \(n\)-ary, if it already holds for \(t_1, ... t_n\).</p> <hr/> <h2 id="well-formed-formulas">Well-formed formulas.</h2> <p>For formulas, we give a very similar definition that makes use of terms.</p> <blockquote> <p><strong>Definition</strong> The set of formulas \(F\) of a language \(L\) is the smallest subset of \(\mathcal{C}_L^*\) satisfying:</p> <ul> <li>It contains all <em>atomic formulas</em>, which are strings of the form: <ol> <li>\(t = s\) for \(s, t \in T\).</li> <li>\(R(t_1, ..., t_n)\) for \(R \in \text{rel}(L)\) an \(n\)-ary relation symbol and \(t_1,...,t_n\in T\).</li> <li>\(\bot\).</li> </ol> </li> <li>It contains all strings of the form: <ol> <li>\(\varphi \land \psi\), \(\varphi \lor \psi\), \(\varphi \rightarrow \psi\), \(\lnot \varphi\), for \(\varphi, \psi \in F\).</li> <li>\(\forall x \varphi\), \(\exists x \varphi\) for \(x\) a variable, \(\psi \in F\).</li> </ol> </li> </ul> </blockquote> <p>The reason that this is well-defined is because again, when a collection of sets satisfying 1. to 5. is intersected, this intersection satisfies 1. to 5. as well.</p> <p>This definition enables us to have an induction principle on \(F\) as well. That is:</p> <blockquote> <p><strong>Induction Principle on Formulas</strong> If some statement holds for all atomic formulas, and if we have that (if the statement holds for \(\varphi \in F\) and \(\psi \in F\), then it holds for \(\varphi \land \psi\), \(\varphi \lor \psi\), \(\varphi \rightarrow \psi\), \(\lnot \varphi\), \(\forall x \varphi\) and for \(\exists x \varphi\) for \(x\)), then the statement holds for all \(L\)-formulas. <strong>Proof</strong> Let \(E\) be the set of \(L\)-formulas for which the statement holds. Since it is given that \(E\) satisfies 1. to 5., it follows by minimality of \(F\) that \(F\subset E\), so we are done.</p> </blockquote> <p>With this induction principle, it is now simple to prove a recursion principle:</p> <blockquote> <p><strong>Recursion Principle on Formulas</strong> Let \(V\) be the set of variables, \(A\) the set of atomic formulas and \(X\) some arbitrary set, with functions: \(f_a:A \rightarrow X\) \(f_\land, f_\lor, f_\rightarrow: X\times X\rightarrow X\) \(f_\lnot: X \rightarrow X\) \(f_\forall, f_\exists: V\times X \rightarrow X\) Then there is a unique function \(f: F\rightarrow X\) that satisfies: \(f(\varphi) = f_a(\varphi)\) if \(\varphi\) is atomic \(f(\varphi) = f_\land(f(\chi), f(\psi))\) if \(\varphi\) is \(\chi \land \psi\) \(f(\varphi) = f_\lor(f(\chi), f(\psi))\) if \(\varphi\) is \(\chi \lor \psi\) \(f(\varphi) = f_\rightarrow(f(\chi), f(\psi))\) if \(\varphi\) is \(\chi \rightarrow \psi\) \(f(\varphi) = f_\lnot(f(\psi))\) if \(\varphi\) is \(\lnot \psi\) \(f(\varphi) = f_\forall(x, f(\psi))\) if \(\varphi\) is \(\forall x \psi\) \(f(\varphi) = f_\exists(x, f(\psi))\) if \(\varphi\) is \(\exists x \psi\)</p> </blockquote> <p>Notee: try not to confuse (meta) equalities with semtences using the <em>equality symbol</em>.</p> <blockquote> <p><strong>Proof</strong> (Sketch)</p> <ul> <li>Unicity: let \(f,g\) both satisfy the recursion and let \(\psi\) be the <em>shortest</em> formula for which \(f(\psi) \not = g(\psi)\). If \(\psi\) is atomic, we see that this is not possible because \(f,g\) are both fixed as \(f_a\) on atomic formulas. So \(\psi\) is composite. We can exhaust all cases and in every case we have to conclude that not all shorter subformula of \(\psi\) can have the exact same image under \(f\) as under \(g\), hence \(\psi\) is not shortest and we get a contradiction.</li> </ul> </blockquote> <p>This means we can now safely define functions by recursion on formulas. The principle example of this is of course substitution:</p> <blockquote> <p><strong>Substitution on \(L\)-formulas</strong> For \(\varphi \in F\), \(x\in V\) and \(s\in T\), we define \(\varphi[s/x]\) by recursion:</p> <ul> <li>\(\varphi[s/x] = (t_1[s/x]=t_2[s/x])\) if \(\varphi = (t_1=t_2)\) and likewise we just substitute on terms for other atomic formulas.</li> <li>\((\psi _ \chi)[s/x] = (\psi[s/x] _ \chi[s/x])\) for \(_ \in \{\land,\lor,\rightarrow\}\)</li> <li>$$(\lnot \psi)[s/x] = \lnot(\psi[s/x])</li> <li>\((\forall y \psi)[s/x] = \forall y (\psi[s/x])\) if \(y \not = x\), otherwise \((\forall x \psi)[s/x] = \forall x \psi\)</li> <li>\((\exists y \psi)[s/x] = \exists y (\psi[s/x])\) if \(y \not = x\), otherwise \((\exists x \psi)[s/x] = \exists x \psi\)</li> </ul> </blockquote> <p>The above definition is interesting: rather than defining what a <em>bound</em> variable is and explaining why bound variables should not be substituted, we first explicitly state substitution rules, and from this we can define what it means for a variable to <em>occur</em> in a formula and to be <em>bounded</em>. A variable is bounded exactly when it is <em>not replaced by substitution</em>!</p> <blockquote> <p><strong>Definition</strong> (occurrence, bounded, free, closed) Let \(\varphi \in F\).</p> <ul> <li>An <em>occurrence</em> of \(x\in V\) in \(\varphi\) is a natural number \(i\) such that the \(i-th\) elemnt of the string \(\varphi\) is \(x\).</li> <li>If \(i\) is an occurrence of \(x\) in \(\varphi\), and let \(u\in V\) not occur in \(\varphi\). Then the occurrence \(i\) of \(x\) is called <em>bound</em> if the \(i\)-th element of \(\varphi[u/x]\) is \(x\).</li> <li><em>free</em> occurrences are those occurrences that are not bound.</li> <li>A formula that has no free occurrences of any variable \(x\in V\) is called <em>closed</em>, or also a <em>sentence</em>.</li> </ul> </blockquote> <h2 id="legitimacy-of-substitutions">Legitimacy of substitutions</h2> <p>Next, I will point out something that will immediately make you think that there is a hiat in our definitions so far. Suppose I give you the formula \(\varphi = \forall x R(x,y)\). It expresses a property for \(y\), you could say. It should mean the same as \(\forall x R(x,y)\). Yet if we substitute the term \(f(x,z)\) for \(y\), we get two formulas that seem to have wildly different semantics:</p> <blockquote> <p>\(\forall x R(x, f(x,z))\) versus \(\forall u R(u, f(x,z))\)</p> </blockquote> <p>This cannot be right. The problem is precisely that occurences of some variables (namely \(x\)) in the substituted term \(t\) get bound in \(\varphi[t/y]\). Otherwise, this bifurcation of semantics would not happen. Hence, we make this type of substitution <em>non-legitimate</em>. Closed terms (no free variables in the term, that is) are of course always legitimate to substitute.</p> <h2 id="structures-and-interpretation-defining-truth">Structures and interpretation: defining truth</h2> <p>So far, we have not yet spoken of the semantics or meaning of f.o.l.. Only in the previous section, I alluded to it in order to motivate legitimacy of substitutions, but I could have also thrown it at you without any motivation, and if you were naive and didn’t have an idea of what the logical connectives etcetera <em>meant</em>, we might as well have used completely different symbols with no apparent semantics such as tables, chairs and beer mugs, and once we have developed a formal system to manipulate these syntactically it would make no difference as to which relationships between the names we would be able to derive.</p> <p>But we want to do logic because we want to understand our reasoning, and we want to be sure that the abstract systems defined to study it, actually matches our interpretation (semantics) or “understanding” of logic, whatever that means. As mathematicians, we value a rigorous definition of this “interpretation” and these “semantics” as well, so we develop them using <em>model theory</em>.</p> <p>The basic idea is that we take, on our meta-level from which we study the formal wff’s, a meta-level set with on it \(n\)-ary functions and relations (not the symbols, but actual functions and relations from set theory). These we call the <em>interpretations</em> of the function and relation <em>symbols</em> in the logical sentences. We then recursively define what it means to interpret <em>terms</em>, then <em>closed formulas</em> and from this we derive a definition of truth. The development of this theory is largely attributed to Tarski. Let’s begin.</p> <hr/> <blockquote> <p><strong>\(L\)-structure</strong> an \(L\)-<em>structure</em> \(M\) is a <em>nonempty</em> set \(M\) together with:</p> <ul> <li>for every constant \(c \in \text{con}(L)\) an element \(c^M\in M\).</li> <li>for every \(n\) for every \(n\)-ary function symbol \(f\in\text{fun}(L)\) a function \(f^M:M^n \rightarrow M\).</li> <li>for every \(n\) for every \(n\)-ary relation symbol \(R\in \text{rel}(L)\) a subset \(R\subset M^n\)</li> </ul> </blockquote> <p>We call \(c^M\) the interpretation of \(c\) in \(M\), and the same goes for \(f^M\) and \(R^M\). first, we define the language \(L_M\) for \(L\) a language and \(M\) an \(L\)-structure to be the language that has the same function symbols and relation symbols of \(L\), but now as its constants it has \(\text{con}(L_M) = \text{con}(L)\cup M\). As an example, we can take \(L_{ring}\), the language of rings, and consider the \(L\)-structure \(M = \mathbb{Z}_3 = \{\bar0, \bar1\, \bar3\}\). Then \(\text{con}(L_M) = \{0,1,\bar0,\bar1,\bar3\}\).</p> <p>Note that if we define \(m^M = m\in M\) for \(m\in \text{con}(L_M)\), then \(M\) is also an \(L_M\)-structure and this is how we will interpret \(L_M\)-constants in \(M\) always. This allows us to recursively define interpretations of <em>closed</em> \(L_M\)-terms:</p> <blockquote> <p><strong>Interpretation of closed terms</strong> For \(t\) an \(L_M\)-term we define the interpretation \(t^M\in M\) as:</p> <ul> <li>for \(t = f(t_1,...,t_n)\), we set \(t^M = f^M(t_1^M, ..., t_n^M)\)</li> <li>for \(t\) a constant \(c\in \text{con}(L)\), we set \(t^M = c^M\)</li> </ul> </blockquote> <p>This is well-defined and unique by structural recursion on terms. Also, note that \(t^M\in M\) can be proved by recursion on terms as well. Finally, I want to remark that there is really not much we can do to interpret <em>open</em> terms. How should we interpret an arbitrary variable anyway? Such an interpretation can for example not depend on the free variable \(x\) itself, because we want \(t[u/x]\) and \(t\) to have the same semantics, for \(u\) another variable that is not yet in \(t\).</p> <p>Next comes “Tarski’s definition of truth”. We write \(M\models\varphi\) and say that \(M\) <em>satisfies</em> \(\varphi\), \(\varphi\) <em>holds in</em> \(M\) or also that \(\varphi\) <em>is true</em> in \(M\). If not \(M\models \varphi\), that is \(M\) does not satisfy \(\varphi\), then we write \(M\not\models\varphi\).</p> <blockquote> <p><strong>Interpretation of closed formulas</strong> For a closed \(L_M\)-formula \(\varphi\) we define the relation \(M\models \varphi\) as:</p> <ul> <li>If \(\varphi\) is a closed atomic formula, it is either \(\bot\), \((t_1=t_2)\) or \(R(t_1,...,t_n)\) for \(t_1, ... , t_n\) closed \(L_M\)-terms. So define: <ul> <li>\(M\models\bot\) never holds.</li> <li>\(M\models (t_1= t_2) iff.\)t_1^M = t_2^M\(in\)M$$.</li> <li>\(M\models R(t_1, ... , t_n)\) iff \((t_1^M, ... , t_n^M )\in R^M\)</li> </ul> </li> <li>If \(\varphi\) is not atomic, it is either a connective followed by one or two closed \(L_M\)-formulas or it is one of the two quantors followed by a variable \(x\) and a \(L_M\)-formula that may have only \(x\) as a free variable but does otherwise not have any other variables with free occurences. Hence define: <ul> <li>\(M\models(\chi\land\psi)\) iff \(M\models\chi\) and \(M\models\psi\)</li> <li>\(M\models(\chi\lor\psi)\) iff \(M\models\chi\) or \(M\models\psi\)</li> <li>\(M\models(\chi\rightarrow\psi)\) iff \(M\models\psi\) whenever \(M\models\chi\)</li> <li>\(M\models(\lnot\psi)\) iff not \(M\models\psi\), hence iff \(M\not\models\psi\).</li> <li>\(M\models\forall x \psi\) iff \(M\models\psi[m/x]\) for all \(m\in M\)</li> <li>\(M\models\exists x \psi\) iff \(M\models[m/x]\) for any \(m\in M\)</li> </ul> </li> </ul> </blockquote> <blockquote> <p><strong>Validity and logical equivalence</strong></p> <ul> <li>An \(L\)-formula \(\varphi\) we call <em>valid</em> if for every \(L\)-structure \(M\) and every substitution of constants of \(M\) for free variables in \(\varphi\) we have \(M\models \varphi\).</li> <li>Two \(L\)-formulas \(\chi\) and \(\psi\) are called equivalent if the formula \(\chi\leftrightarrow\psi\) is valid.</li> </ul> </blockquote> <p>Here we have the shorthand notation \(\chi\leftrightarrow\psi \equiv (\chi\leftarrow\psi) \land (\chi\rightarrow\psi)\)</p> <p>One can then very tediously and bureaucratically prove all the logical equivalences of formulas that we already know very well intuitively, and I will not do that here.</p> <p>An \(L\)-theory \(T\) is simply a set of closed \(L\)-formulas. \(M\) is called a <em>model</em> for \(T\) if it is an \(L\)-structure that satisfies all formulas in \(T\). We call \(T\) <em>consistent</em> if it has (“admits”) a model.</p> <p>An interesting theorem says that \(T\) is consistent iff. every one of its finite subtheories is consistent. This is the so-called <em>compactness theorem</em>, which can indeed be proven via the compactness theorem from topology. Another way of proving it is with <em>ultrafilters</em>. A third way is to just use proof theory and</p> <hr/> <h2 id="well-orders-and-the-limitations-of-first-order-logic">Well-orders and the limitations of first-order logic</h2> <p>A well-order is a set \(W\) with an order relation \(\leq\) on it such that for every nonempty subset \(S\subset W\), \(S\) has a <em>least</em> element \(l\in S\), i.e. for all \(s\in S\) we have \(l\leq s\). Writing this theory in f.o.l. requires us to make a statement about all <em>subsets</em> of \(W\) rather than all <em>elements</em> of \(W\). This is nontrivial, because in the interpretation semantics we described above, we <em>quantify over the elements of a model</em>. So can it be done? The answer is no, and the proof of it makes use of the compactness theorem.</p> <h2 id="proofs">Proofs</h2> <p>We say that \(T\models \varphi\) for \(T\) a \(L\)-theory and \(\varphi\) a \(L\)-sentence, if for every model \(M\) that satisfies \(T\)’s axioms, we have that \(M\models \varphi\).</p> <p>Many frameworks are used to <em>formally</em> prove logical sentences. For such a framework to be acceptable, we want it to be able to be able to generate a formal proof from \(T\) for all \(\varphi\) such that \(T\models\varphi\) (completeness), and vice versa we want it to not be stronger than that, that is, if \(T\vdash \varphi\) (this is the notation we will use for “there exists a proof for \(\varphi\) from assumptions in \(T\)”) then \(T\models\varphi\) (soundness).</p> <p>The set of proofs is defined as the smallest subset of the set of all <em>marked trees</em> over \(F\), that satisfies certain closure properties. I will now explain what marked trees are in this context (if you study cs/discrete maths, you are probably aware that there are 1001 definitions for trees and all sorts of variations) and what the closure properties are.</p> <blockquote> <p><strong>Tree</strong> A (rooted) tree over a set \(X\) is a finite subset \(Y\subset X\) that is:</p> <ul> <li>partially ordered,</li> <li>and has a least element,</li> <li>and for any two \(x,y\in Y\) then \(\{x,y\}\) has an upper bound iff. \(x\leq y\) or \(y\leq x\).</li> </ul> </blockquote> <p>We can display a tree as its Hasse diagram. You can then see that the third rule assures that there is no way two “upward branches” can meet again when we go up the diagram, because</p> <p>The definition given in <em>Sets, Models and Proofs</em> is somewhat different, though I believe that because \(Y\) is finite, you might be able to prove that the two definitions are equivalent:</p> <p><strong>Tree (Sets, Models, Proofs)</strong> A tree over a set \(X\) is a finite subset \(Y\subset X\) that is:</p> <blockquote> <ul> <li>partially ordered,</li> <li>for any \(x\in Y\) the set \(\downarrow (x) = \{y\in Y:y\leq x\}\) is well-ordered.</li> </ul> </blockquote> <p>The <em>maximal elements</em> \(L\subset Y\) of the tree are called <em>leaves</em>, they will act as our assumptions. Important is that assumptions can be <em>marked</em>, so we need to extend our trees to include a <em>marking function</em>.</p> <blockquote> <p><strong>Marked Tree</strong> is a tree with a function \(f:L\rightarrow \{0,1\}\) or equivalently a set \(L_{marked}\subset L\).</p> </blockquote> <p>It is very difficult to get a picture of these abstract definitions in your head. So let me include a picture of a marked tree over \(F\), some set of abstract formulas. My example also happens to be a proof tree, but I will get back to that later.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/prooftree-example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="proof tree image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>In the example, the bottom layer is the root, and the partial order relation is precisely displayed by having two formulas \(\chi\) and \(\psi\) such that \(\chi &lt; \psi\) and that there is no such \(\xi\) that \(\chi &lt; \xi &lt; \psi\) put in the diagram in such a way that \(\psi\) is on a level immediately above \(\chi\) and reachable from \(\chi\) in one step up the tree. Marked leaves are shown as elements [between rectangular brackets]. You should ignore the numbering for now, it is not part of the tree definition in any way.</p> <blockquote> <p><strong>Proof Tree</strong> Given a logical language \(L\), the set \(\mathcal T\) of proof trees is the smallest set of marked trees over the set of \(L\)-formulas that satisfies the following closure properties:</p> </blockquote> <ul> <li>Actually, you can look up the definition in the freely downloadable book <a href="https://www.a-eskwadraat.nl/Onderwijs/Boekweb/Artikel/48/Dictaat/Downloaden"><em>Sets, Models and Proofs</em></a>. I don’t want to literally copy their definition here, that feels too much like plagiarism.</li> <li>The general idea is that every connective and every quantor has an introduction rule to introduce it into a formula, and an elimination rule to eliminate it from a formula. Then there are assumption trees and finally a valid proof is a proof tree where all assumptions (leaves) except maybe those that occur in the <em>assumed</em> theory \(T\) and/or the formula \(\exists x (x=x)\) have been marked.</li> </ul> <p>Once you have read the above definition in the provided book, you can check for yourself that the example tree I provided earlier is indeed a proof tree. It is a proof, or better, a proof schema (since it is more of a template where \(\varphi\) is a completely abstract formula) of the <em>law of excluded third</em>. Any proof for this law makes use of \(\lnot E\), and that is also why in <em>Intuitionistic Logic</em>, where \(\lnot E\) is not one of the closure laws for proof trees, the law of excluded third does not hold.</p>]]></content><author><name></name></author><category term="logic"/><summary type="html"><![CDATA[Something about logic and models for logics (Unfinished)]]></summary></entry><entry><title type="html">Simulating the Geometric distribution in constant time</title><link href="https://matthijsmu.github.io/blog/2023/simulating-geometric-distribution/" rel="alternate" type="text/html" title="Simulating the Geometric distribution in constant time"/><published>2023-08-04T00:00:00+00:00</published><updated>2023-08-04T00:00:00+00:00</updated><id>https://matthijsmu.github.io/blog/2023/simulating-geometric-distribution</id><content type="html" xml:base="https://matthijsmu.github.io/blog/2023/simulating-geometric-distribution/"><![CDATA[<p>On my morning run today I was wondering whether there are faster ways to implement a random generator that samples from a geometric distribution. The naive way is to perform Bernoulli-experiments using uniform distributions until the first success occurs, but this seemed to me hideously expensive as most information of one Bernoulli simulation is thrown away and you could probably do this using some kind of bitwise integer arithmetic. I came up with something and I want to use this post to discuss it with you and establish a connection with simulating the continuous relative of the geometric distribution, that is, the exponential distribution.</p> <hr/> <h2 id="the-geometric-distribution">The Geometric distribution</h2> <p>If \(X_1, X_2, ...\) is an infinite sequence of independently Bernoulli\((p)\)-distributed random variables, then we call \(T_1 := min \{k\in \mathbb N_{\geq 1} \mid X_1 = 1 \}\) geometrically distributed, \(T_1 \sim \text{geom}(p)\).</p> <p>We can interpret \(T_n\) as the number of experiments needed for the first “success” (\(X_i = 1\)) to occur.</p> <p>Using independence of the \(X_i\), we can derive \(\mathbb P[T_1 = k] = ppq^{k-1}\) where \(q = 1-p\).</p> <h2 id="simulating-it-the-textbook-way">Simulating it the textbook way</h2> <p>The naive way of thinking is: If we can simulate a \(X_i \sim \text{Bernoulli}(p)\), then we can use that simulator to simulate a \(X \sim \text{geom}(p)\) by just repeatedly simulating \(X\) until a first success occurs, and counting the total number of experiments that we did.</p> <p>The basic (pseudo-) random number generating capabilities that are included in general-purpose programming language such as <code class="language-plaintext highlighter-rouge">C++</code> are:</p> <ul> <li>a simulator for random integers, which generates a random <code class="language-plaintext highlighter-rouge">int</code> value in the range [<code class="language-plaintext highlighter-rouge">MIN_INT</code>, <code class="language-plaintext highlighter-rouge">MAX_INT</code>].</li> <li>a simulator for the \(\text{uniform}[0,1]\)-distribution, which picks a floating-point type value uniformly random from the range \([0,1]\)</li> </ul> <p>The second capability is usually given as the basis for a \(\text{Bernoulli}(p)\)-generator. Observe that if \(U \sim \text{uniform}[0,1]\), then \(\mathbb P [U \leq p] = p\) exactly, so we get the following very simple procedure:</p> <h2 id="my-problem-with-this-approach--my-alternative">My problem with this approach + my alternative</h2> <p>If you think about the above algorithm in terms of what is happening on the hardware level, you quickly realize that it does way too much work.</p> <ul> <li>Random number generators <a href="https://en.wikipedia.org/wiki/Random_number_generation#Uniform_distributions">natively work with integral types</a>. So generating a <code class="language-plaintext highlighter-rouge">float</code>, <code class="language-plaintext highlighter-rouge">double</code>, etcetera from the range \([0,1]\) consists actually of two steps: first, generate a random <code class="language-plaintext highlighter-rouge">unsigned_integral</code> type value and then divide by <code class="language-plaintext highlighter-rouge">MAX_unsigned_integral</code>.</li> <li>Division is expensive, for one. Also we need something much simpler: we just need a <code class="language-plaintext highlighter-rouge">0</code> with probability \(q\) and a <code class="language-plaintext highlighter-rouge">1</code> with probability \(p\).</li> </ul> <p>Let me just jump to my own idea because the above arguments only make sense when I show you a better implementation to compare against.</p> <h2 id="the-bits-of-random-integers-are-bernoulli-experiments">The bits of random integers are bernoulli experiments</h2> <p>The key point is that if we have an 64-bit <code class="language-plaintext highlighter-rouge">int_A</code> \(\sim\) <code class="language-plaintext highlighter-rouge">random_int()</code>, then all its bits, which I will denote as <code class="language-plaintext highlighter-rouge">int_A[i]</code>, like the integer is some sort of array of booleans, then all bitstrings <code class="language-plaintext highlighter-rouge">int_A[0], ... , int_A[63]</code> are equally likely to occur. This since they all correspond to a unique integer <code class="language-plaintext highlighter-rouge">int_A</code>, and all integer values should by definition of <code class="language-plaintext highlighter-rouge">random_int()</code> occur equally likely.</p> <p>If we marginalize to the distribution of a single <code class="language-plaintext highlighter-rouge">int_A[i]</code>, we realize that it must have a \(\text{Bernoulli}(\frac12)\)-distribution. So when we simulate a random 64-bit integer, we actually get information worth 64 i.i.d. samples from a \(\text{Bernoulli}(\frac12)\)-distribution. This is what I meant when I said that it is a huge detour to first generate a random <code class="language-plaintext highlighter-rouge">int</code>, then divide to a floating-point type in the range \([0,1]\) and only then decide, on 64 bits of information and two expensive arithmetic instructions (floating-point division <em>and</em> floating-point comparison), whether a coin toss is a 0 or a 1.</p> <h2 id="using-bitwise-instructions-to-make-it-even-faster">Using bitwise instructions to make it even faster</h2> <p>With 64 \(\text{Bernoulli}(\frac12)\)-samples in one random number generation, we are left with the task of counting the longest initial segment of failures before a success.</p> <p>The next great feature of integers is that modern CPU architectures come with ALUs that have all kinds of specific circuits for bitwise operations, meaning that manipulating the bits in an integer can be done with dedicated constant-time instructions. For a nice overview, see for example the Wikipedia page on <a href="https://en.wikipedia.org/wiki/Bitwise_operation">Bitwise Operations</a>.</p> <p>Chess engines, for example make heavy use of such cheap bitwise operations when generating moves. They store the positions of one piece type in 64-bit integers called <code class="language-plaintext highlighter-rouge">bitboard</code>s and when they need to calculate all possible fields that, say a bishop, can move to, they take a 64-bit integer which has <code class="language-plaintext highlighter-rouge">1</code>s on the bishop’s rays, shift it so that the bishop is at the center of the “rose”, perform a bitwise <code class="language-plaintext highlighter-rouge">and</code> with the <code class="language-plaintext highlighter-rouge">or</code> of all other pieces, to “mask” out the “blockers”. The blockers-<code class="language-plaintext highlighter-rouge">bitboard</code> is then used as an index in a lookup table that shows the rays of squares onto which the bishop can actually move. And often, it is cheaper to use a hash of the blockers-<code class="language-plaintext highlighter-rouge">bitboard</code> as there are more possible blocker configurations than movement configurations. And this is, in very simple terms, what they mean with “magic bitboards”.</p> <p>In order to compute the square index (that is, the bit 0-63) at which we have the first occurence of a piece, there is the <code class="language-plaintext highlighter-rouge">ctz</code> or count-zero instruction, which computes the number of trailing zeroes starting from the least significant bit. The <code class="language-plaintext highlighter-rouge">ctz</code>-instruction is exactly what we need to compute the initial number of failures!</p> <p>If the instrcution is directly implemented in the hardware, we can regard it as practically constant-time (although on the hardware level, the time theoretically still depends on the actual number of initial zeroes!). In that case we have achieved the following cheap implementation of a random-\(\text{geometric}(p)\)-generator:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;cstlib&gt;</span><span class="cp">
</span>
<span class="k">const</span> <span class="n">SEQUENCE_LENGTH</span> <span class="o">=</span> <span class="n">CHAR_BIT</span> <span class="o">*</span> <span class="nf">max</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(),</span> <span class="k">sizeof</span><span class="p">());</span>

<span class="kt">int</span> <span class="nf">random_geometric</span><span class="p">()</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="kt">int</span> <span class="n">seq</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">rand</span><span class="p">();</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">seq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">x</span> <span class="o">+=</span> <span class="n">SEQUENCE_LENGTH</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>If <code class="language-plaintext highlighter-rouge">seq == 0</code>, we have only failures. This means that the first 64, 48 or 32 experiments (depending on the number of bits <code class="language-plaintext highlighter-rouge">int</code> can contain and the number of bits <code class="language-plaintext highlighter-rouge">std::rand()</code> generates), failed and we have to add 64/48/32 to <code class="language-plaintext highlighter-rouge">x</code> and generate the next sequence of experiments (i.e. the next random integer).</p> <p>Note that calling <code class="language-plaintext highlighter-rouge">std::rand</code> might actually not populate the entire <code class="language-plaintext highlighter-rouge">int</code> if <code class="language-plaintext highlighter-rouge">std::rand()</code> generates shorter integers than the <code class="language-plaintext highlighter-rouge">int</code>-type defined on the machine. Or, the other way around, it might actually generate a longer bitstring and part of this is cut off. In either way, we need that the actual sequence of bernoulli-experiments resides in the shortest of <code class="language-plaintext highlighter-rouge">int</code> and <code class="language-plaintext highlighter-rouge">std::rand()</code>, so we know the length of the sequence is the minimum of those lengths. We can compute the length of <code class="language-plaintext highlighter-rouge">int</code> and <code class="language-plaintext highlighter-rouge">std::rand()</code> by taking the <code class="language-plaintext highlighter-rouge">sizeof()</code> operator. This returns the size in <em>bytes</em>. But “depending on the computer architecture, a byte may consist of 8 or more bits, the exact number being recorded in CHAR_BIT.” (<a href="https://en.cppreference.com/w/cpp/language/sizeof">cppreference</a>, 2023)</p> <p>The extra condition <code class="language-plaintext highlighter-rouge">seq == 0</code> is of course almost never met: the probability of more than \(N\) failures is namely:</p> \[\mathbb P [X &gt; N] = 1 - \sum_{n=0}^N pq^n = p\cdot \frac {1-q^{N+1}}{1-q} = 1 - q^{N+1}\]]]></content><author><name></name></author><category term="statistics,"/><category term="algorithms"/><summary type="html"><![CDATA[Using bitwise integer arithmetic instructions and Diadic rationals.]]></summary></entry></feed>